{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('IRIS.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = iris.drop_duplicates()\n",
    "iris.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "numerical_columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "iris[numerical_columns] = scaler.fit_transform(iris[numerical_columns])\n",
    "\n",
    "iris['species']= encoder.fit_transform(iris['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the feature and target variables\n",
    "y = iris['species']\n",
    "X = iris[numerical_columns]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training report is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.97      0.97      0.97        40\n",
      "           2       0.97      0.97      0.97        36\n",
      "\n",
      "    accuracy                           0.98       110\n",
      "   macro avg       0.98      0.98      0.98       110\n",
      "weighted avg       0.98      0.98      0.98       110\n",
      " \n",
      "\n",
      "The test report is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.98      0.97      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#Instantiate the Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "# Create predictions for the sets\n",
    "X_pred = logreg.predict(X_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_report = classification_report(y_train, X_pred)\n",
    "test_report = classification_report(y_test, y_pred)\n",
    "\n",
    "#display the results\n",
    "print('The training report for the Logistic Regresion is:','\\n',train_report, '\\n')\n",
    "print('The test reportfor the Logistic Regression is:', '\\n', test_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training report for Decision tree is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00        40\n",
      "           2       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00       110\n",
      "   macro avg       1.00      1.00      1.00       110\n",
      "weighted avg       1.00      1.00      1.00       110\n",
      " \n",
      "\n",
      "The test report for Decision tree is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.92        37\n",
      "   macro avg       0.91      0.92      0.91        37\n",
      "weighted avg       0.92      0.92      0.92        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#instantiate and fit the Decisoin tree classifier on to the train and test sets\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "#Create the predictions for the train and test set\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "#Create a classification report that will give the metrics for succes\n",
    "clf_train_report = classification_report(y_train, y_train_pred)\n",
    "clf_test_report = classification_report(y_test, y_test_pred)\n",
    "#Print the results of theclassification report\n",
    "print('The training report for Decision tree is:','\\n',clf_train_report, '\\n')\n",
    "print('The test report for Decision tree is:', '\\n', clf_test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training report for SVM is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.97      0.97      0.97        40\n",
      "           2       0.97      0.97      0.97        36\n",
      "\n",
      "    accuracy                           0.98       110\n",
      "   macro avg       0.98      0.98      0.98       110\n",
      "weighted avg       0.98      0.98      0.98       110\n",
      " \n",
      "\n",
      "The test report for SVM tree is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.95        37\n",
      "   macro avg       0.94      0.94      0.94        37\n",
      "weighted avg       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf', random_state=42)\n",
    "svc.fit(X_train,y_train)\n",
    "\n",
    "svm_train_pred = svc.predict(X_train)\n",
    "svm_test_pred = svc.predict(X_test)\n",
    "\n",
    "svm_train_report = classification_report(y_train, svm_train_pred)\n",
    "svm_test_report = classification_report(y_test, svm_test_pred)\n",
    "\n",
    "print('The training report for SVM is:','\\n',svm_train_report, '\\n')\n",
    "print('The test report for SVM tree is:', '\\n', svm_test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training report for SVM is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00        40\n",
      "           2       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00       110\n",
      "   macro avg       1.00      1.00      1.00       110\n",
      "weighted avg       1.00      1.00      1.00       110\n",
      " \n",
      "\n",
      "The test report for SVM tree is: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.95        37\n",
      "   macro avg       0.94      0.94      0.94        37\n",
      "weighted avg       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_train_pred = rfc.predict(X_train)\n",
    "rfc_test_pred = rfc.predict(X_test)\n",
    "\n",
    "rfc_train_report = classification_report(y_train, rfc_train_pred)\n",
    "rfc_test_report = classification_report(y_test, rfc_test_pred)\n",
    "\n",
    "print('The training report for Random Forest Classifier is:','\\n',rfc_train_report, '\\n')\n",
    "print('The test report for the Random Forest Classifier is:', '\\n', rfc_test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "The best parameters are: \n",
      " {'C': 0.01, 'penalty': None} \n",
      "\n",
      "The report for the Logistic Regression is as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.92        37\n",
      "   macro avg       0.91      0.92      0.91        37\n",
      "weighted avg       0.92      0.92      0.92        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tune the Logistic regression model\n",
    "#create a parameter grid for the regression\n",
    "log_param = {'C':[0.01, 0.1, 1, 10, 100],\n",
    "             'penalty':['l1', 'l2', 'elasticnet', None]}\n",
    "#create a grid for these parameters\n",
    "log_grid = GridSearchCV(estimator=logreg, param_grid=log_param, scoring='accuracy',cv=5, verbose=1) \n",
    "#Fit the grid searh model on the train data\n",
    "log_grid.fit(X_train, y_train)\n",
    "#Check o he best paramters\n",
    "print('The best parameters are:','\\n', log_grid.best_params_, '\\n')\n",
    "#Evaluate on the test data\n",
    "log_tuned = log_grid.best_estimator_\n",
    "y_log_tuned = log_tuned.predict(X_test)\n",
    "log_report = classification_report(y_test, y_log_tuned)\n",
    "print('The report for the Logistic Regression is as follows:','\\n',log_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "The best parameters are: \n",
      " {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2} \n",
      "\n",
      "The report for the Decision tree with best estimators is as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.95        37\n",
      "   macro avg       0.94      0.95      0.94        37\n",
      "weighted avg       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tune the parameters for the Decsioin Tree\n",
    "#crate the parameter_grid\n",
    "dt_param = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'sqrt', 'log2']}\n",
    "#Perform the Grid Search\n",
    "dt_grid = GridSearchCV(estimator=clf, param_grid=dt_param,scoring='accuracy', cv = 5, verbose=1)\n",
    "#fit the grid onto the train sets\n",
    "dt_grid.fit(X_train, y_train)\n",
    "#Show the best parameters \n",
    "print('The best parameters are:','\\n', dt_grid.best_params_, '\\n')\n",
    "#Evaluate on the test data\n",
    "dt_tuned = dt_grid.best_estimator_\n",
    "y_dt_tuned = dt_tuned.predict(X_test)\n",
    "dt_report = classification_report(y_test, y_dt_tuned)\n",
    "print('The report for the Decision tree with best estimators is as follows:','\\n',dt_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "The best parameters are: \n",
      " {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} \n",
      "\n",
      "The report for the Random Forest Classiffier with best estimators is as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.95        37\n",
      "   macro avg       0.94      0.94      0.94        37\n",
      "weighted avg       0.95      0.95      0.95        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tune the parameters for the RandomForest models\n",
    "#Create the parameters for the grid search\n",
    "rfc_param = {'n_estimators':[50, 100, 200],\n",
    "             'max_depth':[10, 20, 30],\n",
    "             'min_samples_split':[2,5,10],\n",
    "             'min_samples_leaf':[1, 2, 4],\n",
    "             'max_features':['sqrt', 'log2', None]}\n",
    "#create the grid \n",
    "rfc_grid = GridSearchCV(estimator= rfc, param_grid=rfc_param, scoring = 'accuracy', cv = 5, verbose = 1)\n",
    "#fit the grid onto the traon sets\n",
    "rfc_grid.fit(X_train, y_train)\n",
    "#show the best parameters\n",
    "print('The best parameters are:', '\\n', rfc_grid.best_params_, '\\n')\n",
    "#Evaluate on the test data\n",
    "rfc_tuned = rfc_grid.best_estimator_\n",
    "y_rfc_tuned = rfc_tuned.predict(X_test)\n",
    "#Create a classification report to view the metrics of the tuned model\n",
    "rfc_report = classification_report(y_test, y_rfc_tuned)\n",
    "print('The report for the Random Forest Classiffier with best estimators is as follows:','\\n',rfc_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "The best parameters are: \n",
      " {'C': 1, 'coef0': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'} \n",
      "\n",
      "The report for the Decision tree with best estimators is as follows: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.98      0.97      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tune the parameters for the SVM model\n",
    "#create t parameter grid\n",
    "svm_param = {\"C\":[0.1, 1, 10,100],\n",
    "             'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'gamma':['scale', 'auto'],\n",
    "             'degree':[2, 3, 4],\n",
    "             'coef0':[0.0, 0.5, 1]}\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svc, param_grid=svm_param, scoring='accuracy', cv = 3, verbose =1)\n",
    "#fit the grid onto the train sets\n",
    "svm_grid.fit(X_train, y_train)\n",
    "#Show the best parameters \n",
    "print('The best parameters are:','\\n', svm_grid.best_params_, '\\n')\n",
    "#Evaluate on the test data\n",
    "svm_tuned = svm_grid.best_estimator_\n",
    "y_svm_tuned = svm_tuned.predict(X_test)\n",
    "svm_report = classification_report(y_test, y_svm_tuned)\n",
    "print('The report for the Decision tree with best estimators is as follows:','\\n',svm_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
